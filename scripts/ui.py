import streamlit as st
import subprocess
import os
from pathlib import Path
import shutil
from PIL import Image
import time

# --- é…ç½® ---
GENERATE_SCRIPT = "generate.py"  # æŒ‡å‘ä½ çš„è„šæœ¬è·¯å¾„
TEMP_INPUT_DIR = "temp_web_inputs"
TEMP_OUTPUT_DIR = "temp_web_outputs"

# ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
os.makedirs(TEMP_INPUT_DIR, exist_ok=True)
os.makedirs(TEMP_OUTPUT_DIR, exist_ok=True)

st.set_page_config(page_title="SD LoRA Generator UI", layout="wide")

# --- ä¾§è¾¹æ ï¼šæ¨¡å‹é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹è®¾ç½®")
    
    base_model = st.text_input(
        "Base Model Path / ID", 
        value="./hub/models--runwayml--stable-diffusion-v1-5",
        help="æŒ‡å‘ diffusers æ ¼å¼çš„æ¨¡å‹ç›®å½•æˆ– HuggingFace ID"
    )
    
    device = st.selectbox("Device", ["cuda", "cpu", "mps"], index=0)
    
    st.markdown("---")
    st.subheader("LoRA é…ç½®")
    
    # åŠ¨æ€ LoRA è¾“å…¥
    lora_paths_input = st.text_area(
        "LoRA Paths (æ¯è¡Œä¸€ä¸ª)", 
        value="./lora/lora_final.safetensors",
        help="è¾“å…¥ .safetensors æ–‡ä»¶çš„è·¯å¾„"
    )
    
    lora_weights_input = st.text_input(
        "LoRA Weights (ç©ºæ ¼åˆ†éš”)", 
        value="1.0",
        help="å¯¹åº”ä¸Šé¢çš„ LoRAï¼Œä¾‹å¦‚: 0.8 0.5"
    )
    
    apply_lora_cnet = st.checkbox("Apply LoRA to ControlNet", value=True)
    
    st.markdown("---")
    st.subheader("ControlNet é…ç½®")
    controlnet_paths = st.text_area(
        "ControlNet Paths (æ¯è¡Œä¸€ä¸ª)", 
        value="lllyasviel/sd-controlnet-canny",
        help="HuggingFace ID æˆ–æœ¬åœ°è·¯å¾„"
    )

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¨ Stable Diffusion Generator")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("1. å›¾ç‰‡è¾“å…¥ & æç¤ºè¯")
    
    uploaded_file = st.file_uploader("ä¸Šä¼ åŸå›¾ (img2img)", type=["png", "jpg", "jpeg", "webp"])
    
    control_image_file = st.file_uploader("ä¸Šä¼  ControlNet å‚è€ƒå›¾ (å¯é€‰)", type=["png", "jpg", "jpeg", "webp"], help="å¦‚æœä¸ä¼ ï¼Œé»˜è®¤ä½¿ç”¨åŸå›¾")

    prompt = st.text_area("Positive Prompt", height=100, value="portrait of a girl, masterpiece, best quality")
    negative_prompt = st.text_area("Negative Prompt", height=80, value="lowres, bad anatomy, blurry, worst quality")

    with st.expander("é«˜çº§å‚æ•°è®¾ç½® (Steps, CFG, Size)", expanded=True):
        c1, c2 = st.columns(2)
        width = c1.number_input("Width", value=512, step=64)
        height = c2.number_input("Height", value=768, step=64)
        
        steps = c1.slider("Steps", 10, 100, 28)
        guidance = c2.slider("Guidance Scale", 1.0, 20.0, 7.5)
        strength = st.slider("Denoising Strength", 0.0, 1.0, 0.6, help="é‡ç»˜å¹…åº¦ï¼Œè¶Šå¤§å˜åŒ–è¶Šå¤§")

    generate_btn = st.button("ğŸš€ ç”Ÿæˆå›¾ç‰‡", type="primary", use_container_width=True)

# --- ç”Ÿæˆé€»è¾‘ ---
with col2:
    st.subheader("2. ç”Ÿæˆç»“æœ")
    
    result_placeholder = st.empty()
    logs_placeholder = st.empty()

    if generate_btn:
        if not uploaded_file:
            st.error("âŒ è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼")
        else:
            # 1. ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½•
            input_path = Path(TEMP_INPUT_DIR) / uploaded_file.name
            with open(input_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # å¤„ç† Control Image
            control_arg = []
            if control_image_file:
                c_path = Path(TEMP_INPUT_DIR) / f"control_{control_image_file.name}"
                with open(c_path, "wb") as f:
                    f.write(control_image_file.getbuffer())
                control_arg = ["--control-input", str(c_path)]

            # 2. æ¸…ç†æ—§çš„è¾“å‡º
            if os.path.exists(TEMP_OUTPUT_DIR):
                shutil.rmtree(TEMP_OUTPUT_DIR)
            os.makedirs(TEMP_OUTPUT_DIR, exist_ok=True)

            # 3. æ„å»ºå‘½ä»¤è¡Œå‚æ•°
            # è§£æå¤šè¡Œè¾“å…¥
            lora_list = [l.strip() for l in lora_paths_input.split('\n') if l.strip()]
            cnet_list = [c.strip() for c in controlnet_paths.split('\n') if c.strip()]
            weights_list = lora_weights_input.strip().split()

            cmd = [
                "python", GENERATE_SCRIPT,
                "--model", base_model,
                "--input", str(input_path),
                "--output", TEMP_OUTPUT_DIR,
                "--prompt", prompt,
                "--negative", negative_prompt,
                "--device", device,
                "--width", str(width),
                "--height", str(height),
                "--steps", str(steps),
                "--guidance", str(guidance),
                "--strength", str(strength),
                "--mode", "single" # å¼ºåˆ¶å•å›¾æ¨¡å¼
            ]

            if lora_list:
                cmd.append("--lora")
                cmd.extend(lora_list)
            
            if weights_list:
                cmd.append("--lora-weights")
                cmd.extend(weights_list)

            if cnet_list:
                cmd.append("--controlnets")
                cmd.extend(cnet_list)

            if apply_lora_cnet:
                cmd.append("--apply-lora-to-controlnet")
            
            cmd.extend(control_arg)

            # 4. æ‰§è¡Œå‘½ä»¤å¹¶æµå¼æ˜¾ç¤ºæ—¥å¿—
            result_placeholder.info("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆ...")
            
            process = subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True, 
                bufsize=1, 
                universal_newlines=True
            )
            
            logs = ""
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    logs += output
                    # ç®€å•æ˜¾ç¤ºæœ€åå‡ è¡Œæ—¥å¿—
                    logs_placeholder.code("\n".join(logs.split('\n')[-5:]), language="bash")
            
            rc = process.poll()
            
            if rc == 0:
                # 5. å¯»æ‰¾å¹¶å±•ç¤ºç”Ÿæˆçš„å›¾ç‰‡
                generated_images = list(Path(TEMP_OUTPUT_DIR).glob("*.png"))
                if generated_images:
                    # æ‰¾åˆ°æœ€æ–°çš„å›¾ç‰‡
                    latest_img = max(generated_images, key=os.path.getctime)
                    image = Image.open(latest_img)
                    result_placeholder.image(image, caption="ç”Ÿæˆç»“æœ", use_container_width=True)
                    st.success(f"ç”ŸæˆæˆåŠŸï¼è€—æ—¶: {logs.split('it/s')[-1] if 'it/s' in logs else 'N/A'}")
                else:
                    result_placeholder.error("è„šæœ¬è¿è¡ŒæˆåŠŸï¼Œä½†æœªæ‰¾åˆ°è¾“å‡ºå›¾ç‰‡ã€‚")
            else:
                result_placeholder.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥å‚æ•°æˆ–æ—¥å¿—ã€‚")
                with st.expander("æŸ¥çœ‹å®Œæ•´é”™è¯¯æ—¥å¿—"):
                    st.text(logs)

# --- é¡µè„šè¯´æ˜ ---
st.markdown("---")
st.markdown("*æ­¤ç•Œé¢æ˜¯ generate.py çš„å‰ç«¯å°è£…ï¼Œç¡®ä¿æ‰€æœ‰è·¯å¾„ï¼ˆæ¨¡å‹ã€LoRAï¼‰ç›¸å¯¹äºè„šæœ¬è¿è¡Œä½ç½®æ˜¯æ­£ç¡®çš„ã€‚*")